{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 11001] getaddrinfo failed>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:1344\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1344\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1336\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1382\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1381\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1382\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1470\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1470\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\http\\client.py:1001\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1000\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m-> 1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\socket.py:829\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    828\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 829\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    830\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\socket.py:964\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    963\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    965\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(original_file_path, data_file_path)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile downloaded and saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mdownload_and_unzip_spamdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mextracted_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m, in \u001b[0;36mdownload_and_unzip_spamdata\u001b[1;34m(url, zip_path, extracted_path, data_file_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_file_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists. Skipping download and extraction.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(zip_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out_file:\n\u001b[0;32m     17\u001b[0m         out_file\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:515\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    512\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    514\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 515\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    518\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:532\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    531\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    533\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:1392\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\anaconda3\\Lib\\urllib\\request.py:1347\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1344\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1345\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1347\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1348\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip'\n",
    "zip_path = 'sms_spam_collection.zip'\n",
    "extracted_path = 'sms_spam_collection'\n",
    "data_file_path = Path(extracted_path) / 'SMSSpamCollection.tsv'\n",
    "\n",
    "def download_and_unzip_spamdata(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, 'wb') as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / 'SMSSpamCollection'\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spamdata(url,zip_path,extracted_path,data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=['Label', 'Text'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df['Label'] == 'spam'].shape[0]\n",
    "    ham_subset = df[df['Label'] == 'ham'].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df['Label'] == 'spam']])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df['Label'] = balanced_df['Label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "\n",
    "    df = df.sample(\n",
    "        frac=1, random_state=123\n",
    "    ).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train.csv', index=None)\n",
    "validation_df.to_csv('validation.csv', index=None)\n",
    "test_df.to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "print(tokenizer.encode('<|endoftext|>', allowed_special={'<|endoftext|>'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data['Text']]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index]['Label']\n",
    "        return(\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(csv_file='train.csv',max_length=None,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(csv_file='validation.csv',max_length=train_dataset.max_length,tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(csv_file='test.csv',max_length=train_dataset.max_length,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "validation_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,  \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimension: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print('Input batch dimension:', input_batch.shape)\n",
    "print('Label batch dimensions:', target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(validation_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"]\n",
    "        )\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'124M'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from gpt_download import load_gpt2_params_from_tf_ckpt\n",
    "from chapter4 import GPTModel\n",
    "models_dir = \"gpt2\"\n",
    "model_dir = os.path.join(models_dir, model_size)\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
    "params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you\"\"\"\"\"\"!\"\"\"\"\"\"!!\n"
     ]
    }
   ],
   "source": [
    "from chapter4 import generate_text_simple\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\"\"\"\"\"\"\"\"!\"\"\"\"\"\"\"\"\"\"\"\"\"!\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG['context_length']\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG['emb_dim'],\n",
    "    out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimension: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimension:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if 1 < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_accuracy_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m calc_accuracy_loader(\n\u001b[0;32m      7\u001b[0m     validation_loader, model, device, num_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m calc_accuracy_loader(\n\u001b[0;32m     11\u001b[0m     test_loader, model, device, num_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n",
      "Cell \u001b[1;32mIn[60], line 15\u001b[0m, in \u001b[0;36mcalc_accuracy_loader\u001b[1;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[0;32m     12\u001b[0m target_batch \u001b[38;5;241m=\u001b[39m target_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     16\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m num_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m predicted_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\chapter4.py:200\u001b[0m, in \u001b[0;36mGPTModel.forward\u001b[1;34m(self, in_idx)\u001b[0m\n\u001b[0;32m    198\u001b[0m x \u001b[38;5;241m=\u001b[39m tok_embeds \u001b[38;5;241m+\u001b[39m pos_embeds  \u001b[38;5;66;03m# Shape [batch_size, num_tokens, emb_size]\u001b[39;00m\n\u001b[0;32m    199\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_emb(x)\n\u001b[1;32m--> 200\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrf_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_norm(x)\n\u001b[0;32m    202\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_head(x)\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\chapter4.py:174\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    172\u001b[0m shortcut \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    173\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)\n\u001b[1;32m--> 174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_shortcut(x)\n\u001b[0;32m    176\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m shortcut  \u001b[38;5;66;03m# Add the original input back\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\chapter4.py:145\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\pilka\\Desktop\\projekty\\llms from scratch\\env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    validation_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.3255497932434084\n",
      "Val loss: 3.0887677669525146\n",
      "Test loss: 2.3095407247543336\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(validation_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "print(f\"Val loss: {val_loss}\")\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "        model, train_loader, validation_loader, optimizer, device, num_epochs, eval_freq, eval_iter\n",
    "):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch, in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, validation_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            validation_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, validation_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            validation_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.859\n",
      "Ep 1 (Step 000050): Train loss 0.631, Val loss 0.618\n",
      "Ep 1 (Step 000100): Train loss 0.498, Val loss 0.561\n",
      "Training accuracy: 72.02% | Validation accuracy: 73.15%\n",
      "Ep 2 (Step 000150): Train loss 0.494, Val loss 0.508\n",
      "Ep 2 (Step 000200): Train loss 0.363, Val loss 0.479\n",
      "Ep 2 (Step 000250): Train loss 0.455, Val loss 0.360\n",
      "Training accuracy: 82.98% | Validation accuracy: 83.89%\n",
      "Ep 3 (Step 000300): Train loss 0.414, Val loss 0.442\n",
      "Ep 3 (Step 000350): Train loss 0.485, Val loss 0.344\n",
      "Training accuracy: 88.75% | Validation accuracy: 93.29%\n",
      "Ep 4 (Step 000400): Train loss 0.220, Val loss 0.190\n",
      "Ep 4 (Step 000450): Train loss 0.204, Val loss 0.196\n",
      "Ep 4 (Step 000500): Train loss 0.147, Val loss 0.091\n",
      "Training accuracy: 94.71% | Validation accuracy: 95.97%\n",
      "Ep 5 (Step 000550): Train loss 0.123, Val loss 0.078\n",
      "Ep 5 (Step 000600): Train loss 0.054, Val loss 0.090\n",
      "Training accuracy: 97.12% | Validation accuracy: 95.97%\n",
      "Training completed in 38.98 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, validation_loader, optimizer, device, num_epochs=num_epochs, eval_freq=50, eval_iter=5\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(\n",
    "        epochs_seen, examples_seen, train_values, val_values, label='loss'\n",
    "):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle='-.', label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor,examples_seen_tensor, train_accs, val_accs, label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.12%\n",
      "Validation accuracy: 95.97%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(validation_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "        text, model, tokenizer, device, max_length=None, pad_token_id=50256\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "    input_ids = input_ids[:min(\n",
    "        max_length, supported_context_length\n",
    "    )]\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wezmy dwa ostatnie bloki do trenowania powinno to istotnie poprawic dzialanie modelu\n",
    "#for param in model.trf.blocks[-2].parameters():\n",
<<<<<<< HEAD
    "#    param.requires_grad = True\n"
=======
    "#    param.requires_grad = True"
>>>>>>> 5dcdcaf (finished most of the content)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
